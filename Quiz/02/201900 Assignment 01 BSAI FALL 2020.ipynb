{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNI8oJFOD5pPzVot3e+qFZ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"5N4U6QZ4iUL8","executionInfo":{"status":"ok","timestamp":1710248578539,"user_tz":-300,"elapsed":528,"user":{"displayName":"Muhammad Hassan Mukhtar","userId":"09411526489529534502"}},"outputId":"d0a74f25-1947-4a4f-c26f-9c5f4e2f5698"},"outputs":[{"output_type":"stream","name":"stdout","text":["        Layer Name  Parameters  Activation Size\n","0            Input           0             3072\n","1         conv2d_2         608             6272\n","2  max_pooling2d_2           0             1568\n","3         conv2d_3        3216             1600\n","4  max_pooling2d_3           0              400\n","5        flatten_1           0              400\n","6          dense_3       48120              120\n","7          dense_4       10164               84\n","8          dense_5         850               10\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","\n","# Define the CNN model\n","def create_cnn_model():\n","    model = tf.keras.models.Sequential([\n","        # Convolutional layer with 8 filters, each 5x5, padding='valid', input shape (32, 32, 3)\n","        tf.keras.layers.Conv2D(8, (5, 5), padding='valid', activation='relu', strides=(1, 1),\n","                               input_shape=(32, 32, 3)),\n","        # Max pooling layer with pool size 2x2\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        # Convolutional layer with 16 filters, each 5x5, padding='valid'\n","        tf.keras.layers.Conv2D(16, (5, 5), padding='valid', activation='relu', strides=(1, 1)),\n","        # Max pooling layer with pool size 2x2\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        # Flatten layer to transition from convolutional layers to fully connected layers\n","        tf.keras.layers.Flatten(),\n","        # Fully connected dense layer with 120 units\n","        tf.keras.layers.Dense(120, activation='relu'),\n","        # Fully connected dense layer with 84 units\n","        tf.keras.layers.Dense(84, activation='relu'),\n","        # Softmax layer\n","        tf.keras.layers.Dense(10, activation='softmax')\n","    ])\n","    return model\n","\n","# Create an instance of the model\n","cnn_model = create_cnn_model()\n","\n","# Initialize lists to store layer names, parameter counts, and activation sizes\n","layer_names = []\n","parameter_counts = []\n","activation_sizes = []\n","\n","# Input layer\n","layer_names.append(\"Input\")\n","parameter_counts.append(0)\n","activation_sizes.append(32 * 32 * 3)  # Assuming input shape is (32, 32, 3)\n","\n","# Iterate through layers and calculate parameters and activation size after each layer\n","for layer in cnn_model.layers:\n","    # Get layer name\n","    layer_names.append(layer.name)\n","\n","    # Calculate number of parameters\n","    if hasattr(layer, 'weights'):\n","        num_params = sum(p.numpy().size for p in layer.weights)\n","        parameter_counts.append(num_params)\n","    else:\n","        parameter_counts.append(0)\n","\n","    # Calculate activation size\n","    if layer.output_shape is not None:\n","        activation_size = 1\n","        for dim in layer.output_shape[1:]:  # Exclude batch dimension\n","            activation_size *= dim\n","        activation_sizes.append(activation_size)\n","    else:\n","        activation_sizes.append(0)\n","\n","# Create DataFrame\n","data = {\n","    'Layer Name': layer_names,\n","    'Parameters': parameter_counts,\n","    'Activation Size': activation_sizes\n","}\n","df = pd.DataFrame(data)\n","\n","# Print DataFrame\n","print(df)\n"]},{"cell_type":"markdown","source":["1. Number of Parameters:\n","\n","   The number of parameters in a layer depends on the type of layer. For convolutional layers and fully connected (dense) layers, the number of parameters can be calculated using the following formulas:\n","\n","   - For Convolutional layers:\n","     Number of Parameters = [ (filter_width * filter_height * input_depth) + 1 ] * num_filters\n","     Where:\n","     - filter_width and filter_height are the width and height of the filter/kernel respectively.\n","     - input_depth is the number of channels in the input.\n","     - num_filters is the number of filters in the layer.\n","     - +1 is added for the bias term associated with each filter.\n","\n","   - For Fully Connected (Dense) layers:\n","     Number of Parameters = (input_size + 1) * output_size\n","     Where:\n","     - input_size is the number of neurons in the previous layer.\n","     - output_size is the number of neurons in the current layer.\n","     - +1 is added for the bias term associated with each neuron.\n","\n","    Note:: No parameters to learn in Input / Pooling Layer.\n","        \n","2. Activation Size:\n","\n","   The activation size after each layer can be computed by multiplying the dimensions of the output shape of the layer (excluding the batch dimension). If the output shape is (batch_size, height, width, channels), then the activation size is given by:\n","   Activation Size = height * width * channels\n"],"metadata":{"id":"B8_WloomqKBX"}}]}